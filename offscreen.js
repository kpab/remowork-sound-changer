/**
 * Offscreen Document for Hand Pose & Face Expression Detection
 * MediaPipe Tasks Vision + face-api.js ã‚’ä½¿ç”¨
 *
 * Note: fetch ãƒãƒªãƒ•ã‚£ãƒ«ã¯ fetch-polyfill.js ã§é©ç”¨æ¸ˆã¿
 */

import { HandLandmarker, FilesetResolver } from './lib/mediapipe/vision_bundle.js';

let handLandmarker = null;
let isInitialized = false;

// è¡¨æƒ…åˆ†æã®åˆæœŸåŒ–çŠ¶æ…‹
let isFaceApiInitialized = false;
let faceApiInitPromise = null;

// åˆæœŸåŒ–ä¸­ã®Promiseã‚’ä¿æŒï¼ˆè¤‡æ•°ã®å‘¼ã³å‡ºã—ã‚’å¾…æ©Ÿã•ã›ã‚‹ãŸã‚ï¼‰
let initPromise = null;

// æœ€å¾Œã®åˆæœŸåŒ–ã‚¨ãƒ©ãƒ¼ã‚’ä¿æŒ
let lastInitError = null;

/**
 * MediaPipe Hand Landmarker ã‚’åˆæœŸåŒ–
 * è¤‡æ•°ã®å‘¼ã³å‡ºã—ãŒã‚ã£ã¦ã‚‚ã€ä¸€åº¦ã ã‘åˆæœŸåŒ–ã‚’å®Ÿè¡Œã—ã€ä»–ã¯å®Œäº†ã‚’å¾…ã¤
 */
async function initDetector() {
  // æ—¢ã«åˆæœŸåŒ–æ¸ˆã¿
  if (isInitialized) return { success: true };

  // åˆæœŸåŒ–ä¸­ãªã‚‰ã€ãã®Promiseã‚’å¾…ã¤
  if (initPromise) {
    console.log('[Offscreen] Waiting for existing initialization...');
    return initPromise;
  }

  // åˆæœŸåŒ–ã‚’é–‹å§‹
  initPromise = (async () => {
    lastInitError = null;

    try {
      console.log('[Offscreen] Initializing MediaPipe Hand Landmarker...');

      // FilesetResolver ã‚’ä½¿ã£ã¦WASMãƒ•ã‚¡ã‚¤ãƒ«ã‚’èª­ã¿è¾¼ã‚€
      const wasmPath = chrome.runtime.getURL('lib/mediapipe/');
      console.log('[Offscreen] WASM path:', wasmPath);

      const vision = await FilesetResolver.forVisionTasks(wasmPath);
      console.log('[Offscreen] FilesetResolver ready');

      const modelPath = chrome.runtime.getURL('lib/mediapipe/hand_landmarker.task');
      console.log('[Offscreen] Model path:', modelPath);

      // Hand Landmarker ã‚’ä½œæˆï¼ˆGPUå„ªå…ˆã€å¤±æ•—æ™‚ã¯CPUã«ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ï¼‰
      try {
        handLandmarker = await HandLandmarker.createFromOptions(vision, {
          baseOptions: {
            modelAssetPath: modelPath,
            delegate: 'GPU'
          },
          runningMode: 'IMAGE',
          numHands: 2
        });
        console.log('[Offscreen] Using GPU delegate');
      } catch (gpuError) {
        const gpuErrorMsg = gpuError?.message || String(gpuError);
        console.warn('[Offscreen] GPU delegate failed, falling back to CPU:', gpuErrorMsg);
        handLandmarker = await HandLandmarker.createFromOptions(vision, {
          baseOptions: {
            modelAssetPath: modelPath,
            delegate: 'CPU'
          },
          runningMode: 'IMAGE',
          numHands: 2
        });
        console.log('[Offscreen] Using CPU delegate');
      }

      isInitialized = true;
      console.log('[Offscreen] MediaPipe Hand Landmarker initialized successfully');
      return { success: true };
    } catch (error) {
      const errorMsg = error?.message || String(error);
      console.error('[Offscreen] Failed to initialize:', errorMsg);
      lastInitError = errorMsg;
      // å¤±æ•—æ™‚ã¯Promiseã‚’ã‚¯ãƒªã‚¢ã—ã¦å†è©¦è¡Œå¯èƒ½ã«ã™ã‚‹
      initPromise = null;
      return { success: false, error: errorMsg };
    }
  })();

  return initPromise;
}

/**
 * 2ç‚¹é–“ã®è·é›¢ã‚’è¨ˆç®—
 */
function distance(p1, p2) {
  return Math.sqrt(Math.pow(p1.x - p2.x, 2) + Math.pow(p1.y - p2.y, 2));
}

/**
 * æ‰‹ã®ãƒ©ãƒ³ãƒ‰ãƒãƒ¼ã‚¯ã‹ã‚‰ã‚¸ã‚§ã‚¹ãƒãƒ£ãƒ¼ã‚’æ¤œå‡º
 *
 * MediaPipe Hand Landmarks:
 * 0: WRIST
 * 1-4: THUMB (CMC, MCP, IP, TIP)
 * 5-8: INDEX (MCP, PIP, DIP, TIP)
 * 9-12: MIDDLE (MCP, PIP, DIP, TIP)
 * 13-16: RING (MCP, PIP, DIP, TIP)
 * 17-20: PINKY (MCP, PIP, DIP, TIP)
 *
 * æ¤œå‡ºå¯¾è±¡ã‚¸ã‚§ã‚¹ãƒãƒ£ãƒ¼ï¼ˆç‰‡æ‰‹ï¼‰:
 * 1. Thumbs Up ğŸ‘: è¦ªæŒ‡ãŒä¸Šå‘ã + 4æœ¬æŒ‡ãŒé–‰ã˜ã¦ã„ã‚‹
 * 2. Peace âœŒï¸: äººå·®ã—æŒ‡ã¨ä¸­æŒ‡ãŒä¼¸ã³ã¦ã„ã‚‹ + ä»–ãŒé–‰ã˜ã¦ã„ã‚‹
 * 3. Open Palm ğŸ‘‹: è¤‡æ•°ã®ãƒ‘ã‚¿ãƒ¼ãƒ³ã§æ¤œå‡º
 *    - ãƒ‘ã‚¿ãƒ¼ãƒ³A: 4æœ¬æŒ‡ãŒä¼¸ã³ã¦ã„ã‚‹ï¼ˆæŒ‡å…ˆãŒPIPã‚ˆã‚Šä¸Šï¼‰
 *    - ãƒ‘ã‚¿ãƒ¼ãƒ³B: æŒ‡ãŒæƒã£ã¦ã„ã‚‹ï¼ˆéš£æ¥ã™ã‚‹æŒ‡å…ˆã®è·é›¢ãŒè¿‘ã„ï¼‰
 *    - ãƒ‘ã‚¿ãƒ¼ãƒ³C: 3æœ¬ä»¥ä¸Šã®æŒ‡ãŒä¼¸ã³ã¦ã„ã‚‹
 *
 * ä¸¡æ‰‹ã‚¸ã‚§ã‚¹ãƒãƒ£ãƒ¼ï¼ˆdetectHeadInHandsé–¢æ•°ã§æ¤œå‡ºï¼‰:
 * - Head in Hands ğŸ˜¢: ä¸¡æ‰‹ãŒé¡”ã®ä¸¡å´ã«ã‚ã‚‹ï¼ˆé ­ã‚’æŠ±ãˆã‚‹ãƒãƒ¼ã‚ºï¼‰
 */
function detectGesture(landmarks) {
  if (!landmarks || landmarks.length === 0) return null;

  // å„æŒ‡ã®ãƒ©ãƒ³ãƒ‰ãƒãƒ¼ã‚¯
  const wrist = landmarks[0];

  // è¦ªæŒ‡
  const thumbTip = landmarks[4];
  const thumbIP = landmarks[3];
  const thumbMCP = landmarks[2];
  const thumbCMC = landmarks[1];
  const thumbExtended = Math.abs(thumbTip.x - wrist.x) > Math.abs(thumbIP.x - wrist.x);
  // è¦ªæŒ‡ãŒä¸Šå‘ãåˆ¤å®šã‚’å³ã—ã: 0.05 â†’ 0.12ï¼ˆã‚ˆã‚Šæ˜ç¢ºã«ä¸Šã‚’å‘ã„ã¦ã„ã‚‹å¿…è¦ã‚ã‚Šï¼‰
  const thumbUp = thumbTip.y < thumbMCP.y - 0.12;
  // è¿½åŠ : è¦ªæŒ‡ãŒæ‰‹ã®ã²ã‚‰ã‚ˆã‚Šæ˜ç¢ºã«ä¸Šã«ã‚ã‚‹
  const thumbClearlyUp = thumbTip.y < wrist.y - 0.05;

  // äººå·®ã—æŒ‡
  const indexTip = landmarks[8];
  const indexPIP = landmarks[6];
  const indexMCP = landmarks[5];
  // æŒ‡ãŒä¼¸ã³ã¦ã„ã‚‹åˆ¤å®šï¼ˆOpen Palmç”¨ï¼‰
  const indexExtended = indexTip.y < indexPIP.y - 0.02;
  // æŒ‡ãŒæ›²ãŒã£ã¦ã„ã‚‹åˆ¤å®šï¼ˆThumbs Upç”¨ï¼‰: ã‚ˆã‚Šå³ã—ã
  const indexBent = indexTip.y > indexPIP.y + 0.03;

  // ä¸­æŒ‡
  const middleTip = landmarks[12];
  const middlePIP = landmarks[10];
  const middleMCP = landmarks[9];
  const middleExtended = middleTip.y < middlePIP.y - 0.02;
  const middleBent = middleTip.y > middlePIP.y + 0.03;

  // è–¬æŒ‡
  const ringTip = landmarks[16];
  const ringPIP = landmarks[14];
  const ringMCP = landmarks[13];
  const ringExtended = ringTip.y < ringPIP.y - 0.02;
  const ringBent = ringTip.y > ringPIP.y + 0.03;

  // å°æŒ‡
  const pinkyTip = landmarks[20];
  const pinkyPIP = landmarks[18];
  const pinkyMCP = landmarks[17];
  const pinkyExtended = pinkyTip.y < pinkyPIP.y - 0.02;
  const pinkyBent = pinkyTip.y > pinkyPIP.y + 0.03;

  // 4æœ¬æŒ‡ã®çŠ¶æ…‹
  const fourFingersClosed = !indexExtended && !middleExtended && !ringExtended && !pinkyExtended;
  // 4æœ¬æŒ‡ãŒæ›²ãŒã£ã¦ã„ã‚‹ï¼ˆThumbs Upç”¨ã®ã‚ˆã‚Šå³ã—ã„åˆ¤å®šï¼‰
  const fourFingersBent = indexBent && middleBent && ringBent && pinkyBent;
  const fourFingersOpen = indexExtended && middleExtended && ringExtended && pinkyExtended;

  // è¦ªæŒ‡ãŒä¸‹ã‚’å‘ã„ã¦ã„ã‚‹ã‹ï¼ˆyåº§æ¨™ãŒMCPã‚ˆã‚Šä¸‹ï¼‰
  const thumbDown = thumbTip.y > thumbMCP.y + 0.05;

  // === Thumbs Up æ¤œå‡º ===
  // è¦ªæŒ‡ãŒæ˜ç¢ºã«ç«‹ã£ã¦ã„ã¦ã€ä»–ã®4æœ¬æŒ‡ãŒæ›²ãŒã£ã¦ã„ã‚‹
  if (thumbUp && thumbClearlyUp && thumbExtended && fourFingersBent) {
    console.log('[Offscreen] Detected: Thumbs Up (strict)');
    return { type: 'thumbsup', emoji: 'ğŸ‘', message: 'ã„ã¤ã§ã‚‚ãŠè©±ã—ã„ã„ã§ã™ã‚ˆï¼ï¼' };
  }

  // === Peace æ¤œå‡º ===
  // äººå·®ã—æŒ‡ã¨ä¸­æŒ‡ãŒä¼¸ã³ã¦ã„ã¦ã€è–¬æŒ‡ã¨å°æŒ‡ãŒé–‰ã˜ã¦ã„ã‚‹
  const peaceSign = indexExtended && middleExtended && !ringExtended && !pinkyExtended;
  if (peaceSign) {
    console.log('[Offscreen] Detected: Peace');
    return { type: 'peace', emoji: 'âœŒï¸', message: 'èª¿å­ã„ã„ã‹ã‚‰èã„ã¦èã„ã¦ï¼ï¼ï¼' };
  }

  // === Open Palm æ¤œå‡ºï¼ˆè¤‡æ•°ãƒ‘ã‚¿ãƒ¼ãƒ³ï¼‰ ===

  // ãƒ‘ã‚¿ãƒ¼ãƒ³A: 4æœ¬æŒ‡ãŒä¼¸ã³ã¦ã„ã‚‹ï¼ˆå¾“æ¥ã®æ¤œå‡ºï¼‰
  if (fourFingersOpen) {
    console.log('[Offscreen] Detected: Open Palm (Pattern A: fingers extended)');
    return { type: 'wave', emoji: 'ğŸ‘‹', message: 'ãŠè©±ã—ã—ãŸã„ã§ã™ï¼ï¼ï¼' };
  }

  // ãƒ‘ã‚¿ãƒ¼ãƒ³B: æŒ‡ãŒæƒã£ã¦ã„ã‚‹ï¼ˆé–‰ã˜ãŸæ‰‹ã®ã²ã‚‰ï¼‰
  // éš£æ¥ã™ã‚‹æŒ‡å…ˆã®è·é›¢ãŒè¿‘ã„ = æŒ‡ãŒæƒã£ã¦ã„ã‚‹
  const indexMiddleDist = distance(indexTip, middleTip);
  const middleRingDist = distance(middleTip, ringTip);
  const ringPinkyDist = distance(ringTip, pinkyTip);
  const avgFingerTipDist = (indexMiddleDist + middleRingDist + ringPinkyDist) / 3;

  // æ‰‹ã®ã²ã‚‰ã®å¹…ï¼ˆäººå·®ã—æŒ‡MCPã‹ã‚‰å°æŒ‡MCPã¾ã§ï¼‰
  const palmWidth = distance(indexMCP, pinkyMCP);

  // æŒ‡å…ˆãŒæƒã£ã¦ã„ã‚‹ï¼ˆéš£æ¥æŒ‡å…ˆã®å¹³å‡è·é›¢ãŒæ‰‹ã®ã²ã‚‰å¹…ã®25%ä»¥ä¸‹ï¼‰
  const fingersAligned = avgFingerTipDist < palmWidth * 0.25;

  // æŒ‡ãŒã‚ã‚‹ç¨‹åº¦ä¼¸ã³ã¦ã„ã‚‹ï¼ˆMCPã‹ã‚‰æŒ‡å…ˆã¾ã§ã®è·é›¢ï¼‰
  const indexLength = distance(indexMCP, indexTip);
  const middleLength = distance(middleMCP, middleTip);
  const ringLength = distance(ringMCP, ringTip);
  const pinkyLength = distance(pinkyMCP, pinkyTip);
  const avgFingerLength = (indexLength + middleLength + ringLength + pinkyLength) / 4;

  // æŒ‡ã®é•·ã•ãŒæ‰‹ã®ã²ã‚‰å¹…ã®40%ä»¥ä¸Šãªã‚‰ã‚ã‚‹ç¨‹åº¦ä¼¸ã³ã¦ã„ã‚‹
  const fingersLongEnough = avgFingerLength > palmWidth * 0.4;

  // ãƒ‘ã‚¿ãƒ¼ãƒ³B: æŒ‡ãŒæƒã£ã¦ã„ã¦ã€ã‚ã‚‹ç¨‹åº¦ä¼¸ã³ã¦ã„ã‚‹
  if (fingersAligned && fingersLongEnough) {
    console.log('[Offscreen] Detected: Open Palm (Pattern B: fingers aligned)');
    return { type: 'wave', emoji: 'ğŸ‘‹', message: 'ãŠè©±ã—ã—ãŸã„ã§ã™ï¼ï¼ï¼' };
  }

  // ãƒ‘ã‚¿ãƒ¼ãƒ³C: æ‰‹ã®ã²ã‚‰ãŒæ­£é¢ã‚’å‘ã„ã¦ã„ã‚‹ï¼ˆå°‘ãªãã¨ã‚‚3æœ¬ã®æŒ‡ãŒä¼¸ã³ã¦ã„ã‚‹ï¼‰
  const extendedCount = [indexExtended, middleExtended, ringExtended, pinkyExtended].filter(Boolean).length;
  if (extendedCount >= 3 && fingersLongEnough) {
    console.log('[Offscreen] Detected: Open Palm (Pattern C: 3+ fingers extended)');
    return { type: 'wave', emoji: 'ğŸ‘‹', message: 'ãŠè©±ã—ã—ãŸã„ã§ã™ï¼ï¼ï¼' };
  }

  // ãã‚Œä»¥å¤–ã®ã‚¸ã‚§ã‚¹ãƒãƒ£ãƒ¼ã¯ç„¡è¦–
  console.log('[Offscreen] No recognized gesture (extended:', extendedCount, 'aligned:', fingersAligned,
    'longEnough:', fingersLongEnough, 'thumbUp:', thumbUp, ')');
  return null;
}

/**
 * ä¸¡æ‰‹ã§ã€Œé ­ã‚’æŠ±ãˆã‚‹ã€ã‚¸ã‚§ã‚¹ãƒãƒ£ãƒ¼ã‚’æ¤œå‡º
 * æ¡ä»¶:
 * - ä¸¡æ‰‹ãŒæ¤œå‡ºã•ã‚Œã¦ã„ã‚‹
 * - ä¸¡æ‰‹ã®æ‰‹é¦–ãŒç”»åƒã®ä¸Šéƒ¨ã«ã‚ã‚‹ï¼ˆé¡”ã®è¿‘ãï¼‰
 * - ä¸¡æ‰‹ã®æ‰‹é¦–ãŒé›¢ã‚Œã¦ã„ã‚‹ï¼ˆé ­ã®ä¸¡å´ï¼‰
 */
function detectHeadInHands(landmarks1, landmarks2) {
  const wrist1 = landmarks1[0];
  const wrist2 = landmarks2[0];

  // ä¸¡æ‰‹é¦–ã®Yåº§æ¨™ãŒç”»åƒä¸Šéƒ¨ã€œä¸­å¤®ä»˜è¿‘ã«ã‚ã‚‹ï¼ˆ0.0ã€œ0.65ã®ç¯„å›²ã€ä¸ŠãŒ0ï¼‰
  // ç·©å’Œ: 0.5 â†’ 0.65ï¼ˆé¡”ã‚ˆã‚Šå°‘ã—ä¸‹ã§ã‚‚OKï¼‰
  const bothHandsHigh = wrist1.y < 0.65 && wrist2.y < 0.65;

  // ä¸¡æ‰‹é¦–ã®Xåº§æ¨™ãŒé›¢ã‚Œã¦ã„ã‚‹ï¼ˆå·¦å³ã«åºƒãŒã£ã¦ã„ã‚‹ï¼‰
  // ç·©å’Œ: 0.3 â†’ 0.2ï¼ˆã‚ˆã‚Šè¿‘ãã¦ã‚‚OKï¼‰
  const handsSpread = Math.abs(wrist1.x - wrist2.x) > 0.2;

  // ä¸¡æ‰‹é¦–ãŒç”»åƒã®ä¸¡ç«¯ã«ã‚ã‚‹ï¼ˆå·¦æ‰‹ã¯å·¦å´ã€å³æ‰‹ã¯å³å´ï¼‰
  // ç·©å’Œ: å³å¯†ãªå·¦å³åˆ†é›¢ã¯ä¸è¦ã€ã‚ã‚‹ç¨‹åº¦é›¢ã‚Œã¦ã„ã‚Œã°OK
  const leftHand = wrist1.x < wrist2.x ? landmarks1 : landmarks2;
  const rightHand = wrist1.x < wrist2.x ? landmarks2 : landmarks1;
  // å·¦æ‰‹ãŒä¸­å¤®ã‚ˆã‚Šå·¦å¯„ã‚Šã€ã¾ãŸã¯å³æ‰‹ãŒä¸­å¤®ã‚ˆã‚Šå³å¯„ã‚Šã§ã‚ã‚Œã°OK
  const properPosition = leftHand[0].x < 0.6 && rightHand[0].x > 0.4;

  // æŒ‡ã®çŠ¶æ…‹ã‚’ãƒã‚§ãƒƒã‚¯ï¼ˆé–‹ã„ã¦ã„ã‚‹ or é–‰ã˜ã¦ã„ã‚‹ã€ã©ã¡ã‚‰ã§ã‚‚OKï¼‰
  // é ­ã‚’æŠ±ãˆã‚‹æ™‚ã¯æŒ‡ãŒé–‹ã„ã¦ã„ã‚‹ã“ã¨ãŒå¤šã„

  if (bothHandsHigh && handsSpread && properPosition) {
    console.log('[Offscreen] Detected: Head in Hands (ä¸¡æ‰‹ã§é ­ã‚’æŠ±ãˆã‚‹)');
    return { type: 'head_in_hands', emoji: 'ğŸ˜¢', message: 'èª¿å­æ‚ªã„ã®ã§æ…°ã‚ã¦ã€‚ã€‚ã€‚ï¼›ï¼›' };
  }

  return null;
}

/**
 * ç”»åƒãƒ‡ãƒ¼ã‚¿ã‹ã‚‰ãƒãƒ³ãƒ‰ã‚µã‚¤ãƒ³ã‚’æ¤œå‡º
 */
async function detectHandSign(imageData) {
  if (!isInitialized || !handLandmarker) {
    const success = await initDetector();
    if (!success) {
      return { success: false, error: 'Detector not initialized' };
    }
  }

  try {
    // ImageData ã‹ã‚‰ ImageBitmap ã‚’ä½œæˆ
    const imageBitmap = await createImageBitmap(
      new ImageData(
        new Uint8ClampedArray(imageData.data),
        imageData.width,
        imageData.height
      )
    );

    // æ‰‹ã‚’æ¤œå‡º
    const results = handLandmarker.detect(imageBitmap);
    imageBitmap.close();

    if (!results.landmarks || results.landmarks.length === 0) {
      return { success: true, gesture: null };
    }

    // ä¸¡æ‰‹ãŒæ¤œå‡ºã•ã‚ŒãŸå ´åˆã€ã€Œé ­ã‚’æŠ±ãˆã‚‹ã€ã‚¸ã‚§ã‚¹ãƒãƒ£ãƒ¼ã‚’ãƒã‚§ãƒƒã‚¯
    if (results.landmarks.length >= 2) {
      const headInHandsGesture = detectHeadInHands(
        results.landmarks[0],
        results.landmarks[1]
      );
      if (headInHandsGesture) {
        return { success: true, gesture: headInHandsGesture };
      }
    }

    // ç‰‡æ‰‹ã®ã‚¸ã‚§ã‚¹ãƒãƒ£ãƒ¼ã‚’ãƒã‚§ãƒƒã‚¯
    const landmarks = results.landmarks[0];
    const gesture = detectGesture(landmarks);

    return { success: true, gesture };
  } catch (error) {
    console.error('[Offscreen] Detection error:', error);
    return { success: false, error: error.message };
  }
}

// ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ãƒªã‚¹ãƒŠãƒ¼
chrome.runtime.onMessage.addListener((message, sender, sendResponse) => {
  if (message.target !== 'offscreen') return false;

  switch (message.type) {
    case 'INIT_DETECTOR':
      initDetector().then(result => {
        sendResponse(result);
      });
      return true;

    case 'DETECT_HAND_SIGN':
      detectHandSign(message.imageData).then(result => {
        sendResponse(result);
      });
      return true;

    case 'GET_STATUS':
      sendResponse({
        initialized: isInitialized,
        initializing: initPromise !== null && !isInitialized,
        lastError: lastInitError,
        faceApiInitialized: isFaceApiInitialized
      });
      return true;

    // è¡¨æƒ…åˆ†æ
    case 'INIT_FACE_API':
      initFaceApi().then(result => {
        sendResponse(result);
      });
      return true;

    case 'ANALYZE_EXPRESSION':
      analyzeExpression(message.imageData).then(result => {
        sendResponse(result);
      });
      return true;

    // æ–‡å­—èµ·ã“ã—é–¢é€£
    case 'START_TRANSCRIPTION':
      sendResponse(startTranscription());
      return true;

    case 'STOP_TRANSCRIPTION':
      sendResponse(stopTranscription());
      return true;

    case 'GET_TRANSCRIPT':
      sendResponse(getTranscript());
      return true;

    default:
      return false;
  }
});

// =============================================
// æ–‡å­—èµ·ã“ã—æ©Ÿèƒ½ (Web Speech API)
// =============================================

let speechRecognition = null;
let isTranscribing = false;
let transcriptText = '';
let lastInterimTranscript = ''; // æœ€å¾Œã®æš«å®šçµæœã‚’ä¿æŒ
let networkErrorRetryCount = 0;
const MAX_NETWORK_RETRIES = 3;
const NETWORK_RETRY_DELAY = 2000; // 2ç§’å¾…ã£ã¦ãƒªãƒˆãƒ©ã‚¤

/**
 * æ–‡å­—èµ·ã“ã—ã‚’é–‹å§‹
 */
function startTranscription() {
  const SpeechRecognition = window.SpeechRecognition || window.webkitSpeechRecognition;
  if (!SpeechRecognition) {
    console.warn('[Offscreen] Web Speech API not supported');
    return { success: false, error: 'Web Speech API not supported' };
  }

  if (isTranscribing) {
    return { success: true, message: 'Already transcribing' };
  }

  transcriptText = '';
  lastInterimTranscript = '';
  isTranscribing = true;
  networkErrorRetryCount = 0;

  speechRecognition = new SpeechRecognition();
  speechRecognition.continuous = true;
  speechRecognition.interimResults = true;
  speechRecognition.lang = 'ja-JP';

  speechRecognition.onresult = (event) => {
    let interimTranscript = '';
    let finalTranscript = '';

    for (let i = event.resultIndex; i < event.results.length; i++) {
      const transcript = event.results[i][0].transcript;
      if (event.results[i].isFinal) {
        finalTranscript += transcript;
      } else {
        interimTranscript += transcript;
      }
    }

    if (finalTranscript) {
      transcriptText += finalTranscript + '\n';
      lastInterimTranscript = ''; // ç¢ºå®šã—ãŸã‚‰ã‚¯ãƒªã‚¢
    } else {
      lastInterimTranscript = interimTranscript; // æš«å®šçµæœã‚’ä¿æŒ
    }

    // Content Scriptã«çµæœã‚’é€ä¿¡
    chrome.runtime.sendMessage({
      type: 'TRANSCRIPTION_RESULT',
      transcript: transcriptText,
      interim: interimTranscript,
      isFinal: !!finalTranscript
    });
  };

  speechRecognition.onerror = (event) => {
    console.warn('[Offscreen] Speech recognition error:', event.error);

    if (event.error === 'network') {
      networkErrorRetryCount++;
      console.log(`[Offscreen] Network error, retry ${networkErrorRetryCount}/${MAX_NETWORK_RETRIES}`);

      if (networkErrorRetryCount <= MAX_NETWORK_RETRIES && isTranscribing) {
        // å†æ¥ç¶šä¸­ã®ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’æ–‡å­—èµ·ã“ã—ã«è¿½åŠ 
        const retryMessage = `\n[â³ å†æ¥ç¶šä¸­... (${networkErrorRetryCount}/${MAX_NETWORK_RETRIES})]\n`;
        chrome.runtime.sendMessage({
          type: 'TRANSCRIPTION_RESULT',
          transcript: transcriptText + retryMessage,
          interim: '',
          isFinal: false
        });

        // å°‘ã—å¾…ã£ã¦ã‹ã‚‰å†æ¥ç¶šã‚’è©¦ã¿ã‚‹
        setTimeout(() => {
          if (isTranscribing && speechRecognition) {
            try {
              speechRecognition.start();
              console.log('[Offscreen] Reconnected after network error');
              // å†æ¥ç¶šæˆåŠŸãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’è¿½åŠ 
              transcriptText += `\n[âœ“ å†æ¥ç¶šæˆåŠŸ]\n`;
              chrome.runtime.sendMessage({
                type: 'TRANSCRIPTION_RESULT',
                transcript: transcriptText,
                interim: '',
                isFinal: false
              });
              networkErrorRetryCount = 0;
            } catch (e) {
              console.warn('[Offscreen] Reconnection failed:', e);
            }
          }
        }, NETWORK_RETRY_DELAY);
        return;
      }

      // ãƒªãƒˆãƒ©ã‚¤ä¸Šé™ã«é”ã—ãŸå ´åˆã¯ã‚¨ãƒ©ãƒ¼ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’æ–‡å­—èµ·ã“ã—ã«è¿½åŠ 
      const errorMessage = `\n[âŒ ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ã‚¨ãƒ©ãƒ¼ï¼šå†æ¥ç¶šã«å¤±æ•—ã—ã¾ã—ãŸ]\n`;
      transcriptText += errorMessage;
      isTranscribing = false;
      chrome.runtime.sendMessage({
        type: 'TRANSCRIPTION_ERROR',
        error: 'network',
        message: 'ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ã‚¨ãƒ©ãƒ¼ï¼šæ–‡å­—èµ·ã“ã—åˆ©ç”¨ä¸å¯',
        transcript: transcriptText
      });
      return;
    }

    if (event.error === 'not-allowed') {
      isTranscribing = false;
      chrome.runtime.sendMessage({
        type: 'TRANSCRIPTION_ERROR',
        error: 'not-allowed',
        message: 'ãƒã‚¤ã‚¯ã¸ã®ã‚¢ã‚¯ã‚»ã‚¹ãŒæ‹’å¦ã•ã‚Œã¾ã—ãŸ'
      });
      return;
    }

    // no-speechã‚¨ãƒ©ãƒ¼ã®å ´åˆã¯å†èµ·å‹•
    if (event.error === 'no-speech' && isTranscribing) {
      setTimeout(() => {
        if (isTranscribing && speechRecognition) {
          try {
            speechRecognition.start();
          } catch (e) {}
        }
      }, 100);
    }
  };

  speechRecognition.onend = () => {
    // å†èµ·å‹•å‰ã«æš«å®šçµæœãŒã‚ã‚Œã°ç¢ºå®šã¨ã—ã¦ä¿å­˜
    if (lastInterimTranscript) {
      transcriptText += lastInterimTranscript + '\n';
      lastInterimTranscript = '';
      // æ›´æ–°ã‚’é€šçŸ¥
      chrome.runtime.sendMessage({
        type: 'TRANSCRIPTION_RESULT',
        transcript: transcriptText,
        interim: '',
        isFinal: true
      });
    }

    // ã¾ã æ–‡å­—èµ·ã“ã—ä¸­ãªã‚‰å†é–‹
    if (isTranscribing) {
      try {
        speechRecognition.start();
      } catch (e) {}
    }
  };

  try {
    speechRecognition.start();
    console.log('[Offscreen] Transcription started');
    return { success: true };
  } catch (e) {
    console.error('[Offscreen] Failed to start transcription:', e);
    isTranscribing = false;
    return { success: false, error: e.message };
  }
}

/**
 * æ–‡å­—èµ·ã“ã—ã‚’åœæ­¢
 */
function stopTranscription() {
  isTranscribing = false;
  if (speechRecognition) {
    try {
      speechRecognition.stop();
    } catch (e) {}
    speechRecognition = null;
  }
  console.log('[Offscreen] Transcription stopped');
  return { success: true, transcript: transcriptText };
}

/**
 * ç¾åœ¨ã®æ–‡å­—èµ·ã“ã—ãƒ†ã‚­ã‚¹ãƒˆã‚’å–å¾—
 */
function getTranscript() {
  return { success: true, transcript: transcriptText, isTranscribing };
}

// =============================================
// è¡¨æƒ…åˆ†ææ©Ÿèƒ½ (face-api.js)
// =============================================

/**
 * XHRã§ãƒ•ã‚¡ã‚¤ãƒ«ã‚’èª­ã¿è¾¼ã‚€ï¼ˆchrome-extension:// URLå¯¾å¿œï¼‰
 */
function loadFileXHR(url, responseType = 'arraybuffer') {
  return new Promise((resolve, reject) => {
    console.log('[Offscreen] XHR loading:', url);
    const xhr = new XMLHttpRequest();
    xhr.open('GET', url, true);
    xhr.responseType = responseType;
    xhr.onload = () => {
      if (xhr.status === 200 || xhr.status === 0) {
        console.log('[Offscreen] XHR loaded:', url);
        resolve(xhr.response);
      } else {
        reject(new Error(`HTTP ${xhr.status} for ${url}`));
      }
    };
    xhr.onerror = (e) => {
      console.error('[Offscreen] XHR error:', url, e);
      reject(new Error('XHR failed for ' + url));
    };
    xhr.send();
  });
}

/**
 * face-api.js ã‚’åˆæœŸåŒ–
 * XHRã§ãƒ¢ãƒ‡ãƒ«ãƒ•ã‚¡ã‚¤ãƒ«ã‚’äº‹å‰ãƒ­ãƒ¼ãƒ‰ã—ã€ã‚«ã‚¹ã‚¿ãƒ IOHandlerã‚’ä½¿ç”¨
 */
async function initFaceApi() {
  if (isFaceApiInitialized) return { success: true };

  if (faceApiInitPromise) {
    console.log('[Offscreen] Waiting for existing face-api initialization...');
    return faceApiInitPromise;
  }

  faceApiInitPromise = (async () => {
    try {
      console.log('[Offscreen] Initializing face-api.js...');

      // face-api.js ãŒã‚°ãƒ­ãƒ¼ãƒãƒ«ã«èª­ã¿è¾¼ã¾ã‚Œã¦ã„ã‚‹ã‹ç¢ºèª
      if (typeof faceapi === 'undefined') {
        throw new Error('face-api.js is not loaded');
      }

      const modelBasePath = chrome.runtime.getURL('lib/face-api/');
      console.log('[Offscreen] Face-api model path:', modelBasePath);

      // Tiny Face Detector ãƒ¢ãƒ‡ãƒ«ã‚’èª­ã¿è¾¼ã¿
      console.log('[Offscreen] Loading Tiny Face Detector...');
      await loadFaceApiModel(faceapi.nets.tinyFaceDetector, modelBasePath, 'tiny_face_detector_model');
      console.log('[Offscreen] Tiny Face Detector loaded');

      // Face Expression ãƒ¢ãƒ‡ãƒ«ã‚’èª­ã¿è¾¼ã¿
      console.log('[Offscreen] Loading Face Expression Net...');
      await loadFaceApiModel(faceapi.nets.faceExpressionNet, modelBasePath, 'face_expression_model');
      console.log('[Offscreen] Face Expression Net loaded');

      isFaceApiInitialized = true;
      console.log('[Offscreen] face-api.js initialized successfully');
      return { success: true };
    } catch (error) {
      const errorMsg = error?.message || String(error);
      console.error('[Offscreen] Failed to initialize face-api:', errorMsg, error);
      faceApiInitPromise = null;
      return { success: false, error: errorMsg };
    }
  })();

  return faceApiInitPromise;
}

/**
 * face-api.jsãƒ¢ãƒ‡ãƒ«ã‚’XHRã§èª­ã¿è¾¼ã‚€
 * TensorFlow.jsã®decodeWeightsã‚’ä½¿ç”¨ã—ã¦weightsMapã‚’ä½œæˆã—ã€loadFromWeightsMapã§èª­ã¿è¾¼ã¿
 */
async function loadFaceApiModel(net, basePath, modelName) {
  // ãƒãƒ‹ãƒ•ã‚§ã‚¹ãƒˆãƒ•ã‚¡ã‚¤ãƒ«ã‚’XHRã§èª­ã¿è¾¼ã¿
  const manifestUrl = basePath + modelName + '-weights_manifest.json';
  console.log('[Offscreen] Loading manifest:', manifestUrl);
  const manifestText = await loadFileXHR(manifestUrl, 'text');
  const manifest = JSON.parse(manifestText);
  console.log('[Offscreen] Manifest loaded, paths:', manifest[0].paths);

  // å…¨ã¦ã®é‡ã¿ãƒ•ã‚¡ã‚¤ãƒ«ã‚’XHRã§èª­ã¿è¾¼ã¿ã€TensorFlow.jsã§ãƒ‡ã‚³ãƒ¼ãƒ‰
  const weightsMap = {};
  for (const group of manifest) {
    for (const path of group.paths) {
      const weightsUrl = basePath + path;
      console.log('[Offscreen] Loading weights:', weightsUrl);
      const weightsBuffer = await loadFileXHR(weightsUrl, 'arraybuffer');
      console.log('[Offscreen] Weights loaded, size:', weightsBuffer.byteLength);

      // TensorFlow.jsã‚’ä½¿ã£ã¦é‡ã¿ã‚’ãƒ‡ã‚³ãƒ¼ãƒ‰
      const weightSpecs = group.weights;
      console.log('[Offscreen] Decoding weights, specs count:', weightSpecs.length);

      try {
        // faceapi.tf.io.decodeWeights ã¯ weightsMap (name -> Tensor) ã‚’è¿”ã™
        const decoded = faceapi.tf.io.decodeWeights(weightsBuffer, weightSpecs);
        console.log('[Offscreen] Decoded weights:', Object.keys(decoded));

        // weightsMapã«ãƒãƒ¼ã‚¸
        for (const [name, tensor] of Object.entries(decoded)) {
          weightsMap[name] = tensor;
        }
      } catch (decodeError) {
        console.error('[Offscreen] Failed to decode weights:', decodeError);
        throw decodeError;
      }
    }
  }

  console.log('[Offscreen] Total weights loaded:', Object.keys(weightsMap).length);

  // face-api.jsã®loadFromUriã‚’ä½¿ç”¨ï¼ˆfetchãƒãƒªãƒ•ã‚£ãƒ«ã§XHRã«å¤‰æ›ã•ã‚Œã‚‹ï¼‰
  // URLã®æœ«å°¾ã«ã‚¹ãƒ©ãƒƒã‚·ãƒ¥ãŒã‚ã‚‹ã“ã¨ã‚’ç¢ºèª
  const normalizedBasePath = basePath.endsWith('/') ? basePath : basePath + '/';
  console.log('[Offscreen] Loading model via loadFromUri:', normalizedBasePath);
  await net.loadFromUri(normalizedBasePath);
  console.log('[Offscreen] Model loaded successfully via loadFromUri');
}

/**
 * è¡¨æƒ…ã‚’åˆ†æ
 * @param {Object} imageData - ç”»åƒãƒ‡ãƒ¼ã‚¿
 * @returns {Object} åˆ†æçµæœï¼ˆæ„Ÿæƒ…ä¿‚æ•°ï¼‰
 */
async function analyzeExpression(imageData) {
  if (!isFaceApiInitialized) {
    const result = await initFaceApi();
    if (!result.success) {
      return { success: false, error: `Face-api init failed: ${result.error}` };
    }
  }

  try {
    // ImageData ã‹ã‚‰ Canvas ã‚’ä½œæˆ
    const canvas = document.getElementById('canvas');
    canvas.width = imageData.width;
    canvas.height = imageData.height;
    const ctx = canvas.getContext('2d');
    ctx.putImageData(
      new ImageData(
        new Uint8ClampedArray(imageData.data),
        imageData.width,
        imageData.height
      ),
      0, 0
    );

    // é¡”æ¤œå‡º + è¡¨æƒ…åˆ†æ
    // TinyFaceDetectorOptions:
    //   inputSize: æ¤œå‡ºã‚°ãƒªãƒƒãƒ‰ã‚µã‚¤ã‚º (128, 160, 224, 320, 416, 512, 608) - å°ã•ã„ã»ã©é«˜é€Ÿã€å¤§ãã„ã»ã©ç²¾åº¦å‘ä¸Š
    //   scoreThreshold: æ¤œå‡ºé–¾å€¤ (0-1) - ä½ã„ã»ã©æ¤œå‡ºã•ã‚Œã‚„ã™ã„
    const detectorOptions = new faceapi.TinyFaceDetectorOptions({
      inputSize: 416,      // ç”»åƒã‚µã‚¤ã‚º640pxã«åˆã‚ã›ã¦å¤§ãã‚ã«è¨­å®šï¼ˆç²¾åº¦å„ªå…ˆï¼‰
      scoreThreshold: 0.05 // æ¤œå‡ºé–¾å€¤ã‚’éå¸¸ã«ä½ãè¨­å®šï¼ˆã»ã¼å…¨ã¦æ¤œå‡ºï¼‰
    });
    const detections = await faceapi
      .detectAllFaces(canvas, detectorOptions)
      .withFaceExpressions();

    if (!detections || detections.length === 0) {
      return { success: true, expressions: null, message: 'é¡”ãŒæ¤œå‡ºã•ã‚Œã¾ã›ã‚“ã§ã—ãŸ' };
    }

    // æœ€åˆã®é¡”ã®è¡¨æƒ…ã‚’å–å¾—
    const expressions = detections[0].expressions;

    // ç”Ÿã®å€¤ã‚’ãƒ­ã‚°å‡ºåŠ›ï¼ˆãƒ‡ãƒãƒƒã‚°ç”¨ï¼‰
    console.log('[Offscreen] Raw expressions:', {
      happy: expressions.happy.toFixed(4),
      sad: expressions.sad.toFixed(4),
      angry: expressions.angry.toFixed(4),
      fearful: expressions.fearful.toFixed(4),
      disgusted: expressions.disgusted.toFixed(4),
      surprised: expressions.surprised.toFixed(4),
      neutral: expressions.neutral.toFixed(4)
    });

    // æ„Ÿæƒ…ä¿‚æ•°ã«å¤‰æ›ï¼ˆ0-100ã®ã‚¹ã‚³ã‚¢ã€å°æ•°ç‚¹1æ¡ï¼‰
    const emotionScores = {
      happy: Math.round(expressions.happy * 1000) / 10,      // å¹¸ç¦ä¿‚æ•°
      sad: Math.round(expressions.sad * 1000) / 10,          // æ‚²å“€ä¿‚æ•°
      angry: Math.round(expressions.angry * 1000) / 10,      // æ†¤æ€’ä¿‚æ•°
      fearful: Math.round(expressions.fearful * 1000) / 10,  // ææ€–ä¿‚æ•°
      disgusted: Math.round(expressions.disgusted * 1000) / 10, // å«Œæ‚ªä¿‚æ•°
      surprised: Math.round(expressions.surprised * 1000) / 10, // é©šæ„•ä¿‚æ•°
      neutral: Math.round(expressions.neutral * 1000) / 10   // å¹³é™ä¿‚æ•°
    };

    // æœ€ã‚‚é«˜ã„æ„Ÿæƒ…ã‚’ç‰¹å®š
    let dominant = 'neutral';
    let maxScore = emotionScores.neutral;
    for (const [emotion, score] of Object.entries(emotionScores)) {
      if (score > maxScore) {
        maxScore = score;
        dominant = emotion;
      }
    }

    console.log('[Offscreen] Expression analysis:', emotionScores, 'dominant:', dominant);

    return {
      success: true,
      expressions: emotionScores,
      dominant: dominant,
      faceCount: detections.length
    };
  } catch (error) {
    console.error('[Offscreen] Expression analysis error:', error);
    return { success: false, error: error.message };
  }
}

// åˆæœŸåŒ–ã‚’é–‹å§‹
initDetector();
