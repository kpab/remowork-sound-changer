/**
 * Offscreen Document for Hand Pose Detection
 * MediaPipe Tasks Vision ã‚’ä½¿ç”¨ã—ãŸæœ¬æ ¼çš„ãªæ‰‹æ¤œå‡º
 */

import { HandLandmarker, FilesetResolver } from './lib/mediapipe/vision_bundle.js';

let handLandmarker = null;
let isInitialized = false;

// åˆæœŸåŒ–ä¸­ã®Promiseã‚’ä¿æŒï¼ˆè¤‡æ•°ã®å‘¼ã³å‡ºã—ã‚’å¾…æ©Ÿã•ã›ã‚‹ãŸã‚ï¼‰
let initPromise = null;

// æœ€å¾Œã®åˆæœŸåŒ–ã‚¨ãƒ©ãƒ¼ã‚’ä¿æŒ
let lastInitError = null;

/**
 * MediaPipe Hand Landmarker ã‚’åˆæœŸåŒ–
 * è¤‡æ•°ã®å‘¼ã³å‡ºã—ãŒã‚ã£ã¦ã‚‚ã€ä¸€åº¦ã ã‘åˆæœŸåŒ–ã‚’å®Ÿè¡Œã—ã€ä»–ã¯å®Œäº†ã‚’å¾…ã¤
 */
async function initDetector() {
  // æ—¢ã«åˆæœŸåŒ–æ¸ˆã¿
  if (isInitialized) return { success: true };

  // åˆæœŸåŒ–ä¸­ãªã‚‰ã€ãã®Promiseã‚’å¾…ã¤
  if (initPromise) {
    console.log('[Offscreen] Waiting for existing initialization...');
    return initPromise;
  }

  // åˆæœŸåŒ–ã‚’é–‹å§‹
  initPromise = (async () => {
    lastInitError = null;

    try {
      console.log('[Offscreen] Initializing MediaPipe Hand Landmarker...');

      // FilesetResolver ã‚’ä½¿ã£ã¦WASMãƒ•ã‚¡ã‚¤ãƒ«ã‚’èª­ã¿è¾¼ã‚€
      const wasmPath = chrome.runtime.getURL('lib/mediapipe/');
      console.log('[Offscreen] WASM path:', wasmPath);

      const vision = await FilesetResolver.forVisionTasks(wasmPath);
      console.log('[Offscreen] FilesetResolver ready');

      const modelPath = chrome.runtime.getURL('lib/mediapipe/hand_landmarker.task');
      console.log('[Offscreen] Model path:', modelPath);

      // Hand Landmarker ã‚’ä½œæˆï¼ˆGPUå„ªå…ˆã€å¤±æ•—æ™‚ã¯CPUã«ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ï¼‰
      try {
        handLandmarker = await HandLandmarker.createFromOptions(vision, {
          baseOptions: {
            modelAssetPath: modelPath,
            delegate: 'GPU'
          },
          runningMode: 'IMAGE',
          numHands: 2
        });
        console.log('[Offscreen] Using GPU delegate');
      } catch (gpuError) {
        const gpuErrorMsg = gpuError?.message || String(gpuError);
        console.warn('[Offscreen] GPU delegate failed, falling back to CPU:', gpuErrorMsg);
        handLandmarker = await HandLandmarker.createFromOptions(vision, {
          baseOptions: {
            modelAssetPath: modelPath,
            delegate: 'CPU'
          },
          runningMode: 'IMAGE',
          numHands: 2
        });
        console.log('[Offscreen] Using CPU delegate');
      }

      isInitialized = true;
      console.log('[Offscreen] MediaPipe Hand Landmarker initialized successfully');
      return { success: true };
    } catch (error) {
      const errorMsg = error?.message || String(error);
      console.error('[Offscreen] Failed to initialize:', errorMsg);
      lastInitError = errorMsg;
      // å¤±æ•—æ™‚ã¯Promiseã‚’ã‚¯ãƒªã‚¢ã—ã¦å†è©¦è¡Œå¯èƒ½ã«ã™ã‚‹
      initPromise = null;
      return { success: false, error: errorMsg };
    }
  })();

  return initPromise;
}

/**
 * æ‰‹ã®ãƒ©ãƒ³ãƒ‰ãƒãƒ¼ã‚¯ã‹ã‚‰ã‚¸ã‚§ã‚¹ãƒãƒ£ãƒ¼ã‚’æ¤œå‡º
 * æ‰‹ãŒæ¤œå‡ºã•ã‚ŒãŸã‚‰ã€ŒãŠè©±ã—OKã€ã‚’è¿”ã™
 */
function detectGesture(landmarks) {
  if (!landmarks || landmarks.length === 0) return null;

  // æ‰‹ãŒæ¤œå‡ºã•ã‚ŒãŸ = ãŠè©±ã—OK
  return { type: 'talk_ok', emoji: 'ğŸ™‹', message: 'ãŠè©±ã—OKã§ã™' };
}

/**
 * ç”»åƒãƒ‡ãƒ¼ã‚¿ã‹ã‚‰ãƒãƒ³ãƒ‰ã‚µã‚¤ãƒ³ã‚’æ¤œå‡º
 */
async function detectHandSign(imageData) {
  if (!isInitialized || !handLandmarker) {
    const success = await initDetector();
    if (!success) {
      return { success: false, error: 'Detector not initialized' };
    }
  }

  try {
    // ImageData ã‹ã‚‰ ImageBitmap ã‚’ä½œæˆ
    const imageBitmap = await createImageBitmap(
      new ImageData(
        new Uint8ClampedArray(imageData.data),
        imageData.width,
        imageData.height
      )
    );

    // æ‰‹ã‚’æ¤œå‡º
    const results = handLandmarker.detect(imageBitmap);
    imageBitmap.close();

    if (!results.landmarks || results.landmarks.length === 0) {
      return { success: true, gesture: null };
    }

    // æœ€åˆã«æ¤œå‡ºã•ã‚ŒãŸæ‰‹ã®ãƒ©ãƒ³ãƒ‰ãƒãƒ¼ã‚¯
    const landmarks = results.landmarks[0];
    const gesture = detectGesture(landmarks);

    return { success: true, gesture };
  } catch (error) {
    console.error('[Offscreen] Detection error:', error);
    return { success: false, error: error.message };
  }
}

// ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ãƒªã‚¹ãƒŠãƒ¼
chrome.runtime.onMessage.addListener((message, sender, sendResponse) => {
  if (message.target !== 'offscreen') return false;

  switch (message.type) {
    case 'INIT_DETECTOR':
      initDetector().then(result => {
        sendResponse(result);
      });
      return true;

    case 'DETECT_HAND_SIGN':
      detectHandSign(message.imageData).then(result => {
        sendResponse(result);
      });
      return true;

    case 'GET_STATUS':
      sendResponse({
        initialized: isInitialized,
        initializing: initPromise !== null && !isInitialized,
        lastError: lastInitError
      });
      return true;

    // æ–‡å­—èµ·ã“ã—é–¢é€£
    case 'START_TRANSCRIPTION':
      sendResponse(startTranscription());
      return true;

    case 'STOP_TRANSCRIPTION':
      sendResponse(stopTranscription());
      return true;

    case 'GET_TRANSCRIPT':
      sendResponse(getTranscript());
      return true;

    default:
      return false;
  }
});

// =============================================
// æ–‡å­—èµ·ã“ã—æ©Ÿèƒ½ (Web Speech API)
// =============================================

let speechRecognition = null;
let isTranscribing = false;
let transcriptText = '';

/**
 * æ–‡å­—èµ·ã“ã—ã‚’é–‹å§‹
 */
function startTranscription() {
  const SpeechRecognition = window.SpeechRecognition || window.webkitSpeechRecognition;
  if (!SpeechRecognition) {
    console.warn('[Offscreen] Web Speech API not supported');
    return { success: false, error: 'Web Speech API not supported' };
  }

  if (isTranscribing) {
    return { success: true, message: 'Already transcribing' };
  }

  transcriptText = '';
  isTranscribing = true;

  speechRecognition = new SpeechRecognition();
  speechRecognition.continuous = true;
  speechRecognition.interimResults = true;
  speechRecognition.lang = 'ja-JP';

  speechRecognition.onresult = (event) => {
    let interimTranscript = '';
    let finalTranscript = '';

    for (let i = event.resultIndex; i < event.results.length; i++) {
      const transcript = event.results[i][0].transcript;
      if (event.results[i].isFinal) {
        finalTranscript += transcript;
      } else {
        interimTranscript += transcript;
      }
    }

    if (finalTranscript) {
      transcriptText += finalTranscript + '\n';
    }

    // Content Scriptã«çµæœã‚’é€ä¿¡
    chrome.runtime.sendMessage({
      type: 'TRANSCRIPTION_RESULT',
      transcript: transcriptText,
      interim: interimTranscript,
      isFinal: !!finalTranscript
    });
  };

  speechRecognition.onerror = (event) => {
    console.warn('[Offscreen] Speech recognition error:', event.error);

    if (event.error === 'network') {
      isTranscribing = false;
      chrome.runtime.sendMessage({
        type: 'TRANSCRIPTION_ERROR',
        error: 'network',
        message: 'ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ã‚¨ãƒ©ãƒ¼ï¼šæ–‡å­—èµ·ã“ã—åˆ©ç”¨ä¸å¯'
      });
      return;
    }

    if (event.error === 'not-allowed') {
      isTranscribing = false;
      chrome.runtime.sendMessage({
        type: 'TRANSCRIPTION_ERROR',
        error: 'not-allowed',
        message: 'ãƒã‚¤ã‚¯ã¸ã®ã‚¢ã‚¯ã‚»ã‚¹ãŒæ‹’å¦ã•ã‚Œã¾ã—ãŸ'
      });
      return;
    }

    // no-speechã‚¨ãƒ©ãƒ¼ã®å ´åˆã¯å†èµ·å‹•
    if (event.error === 'no-speech' && isTranscribing) {
      setTimeout(() => {
        if (isTranscribing && speechRecognition) {
          try {
            speechRecognition.start();
          } catch (e) {}
        }
      }, 100);
    }
  };

  speechRecognition.onend = () => {
    // ã¾ã æ–‡å­—èµ·ã“ã—ä¸­ãªã‚‰å†é–‹
    if (isTranscribing) {
      try {
        speechRecognition.start();
      } catch (e) {}
    }
  };

  try {
    speechRecognition.start();
    console.log('[Offscreen] Transcription started');
    return { success: true };
  } catch (e) {
    console.error('[Offscreen] Failed to start transcription:', e);
    isTranscribing = false;
    return { success: false, error: e.message };
  }
}

/**
 * æ–‡å­—èµ·ã“ã—ã‚’åœæ­¢
 */
function stopTranscription() {
  isTranscribing = false;
  if (speechRecognition) {
    try {
      speechRecognition.stop();
    } catch (e) {}
    speechRecognition = null;
  }
  console.log('[Offscreen] Transcription stopped');
  return { success: true, transcript: transcriptText };
}

/**
 * ç¾åœ¨ã®æ–‡å­—èµ·ã“ã—ãƒ†ã‚­ã‚¹ãƒˆã‚’å–å¾—
 */
function getTranscript() {
  return { success: true, transcript: transcriptText, isTranscribing };
}

// åˆæœŸåŒ–ã‚’é–‹å§‹
initDetector();
